# üß† Interpretation Agent

Cet agent est le "cerveau" du syst√®me multi-agents. Il est responsable de comprendre les demandes de l'utilisateur (texte ou voix) et de les transformer en une sp√©cification technique structur√©e (`AgentSpec`) que d'autres agents pourront ex√©cuter.

## üöÄ Fonctionnalit√©s

*   **Conversation Gateway** : Un assistant conversationnel qui discute avec l'utilisateur pour affiner son besoin avant de lancer l'interpr√©tation.
*   **Analyse du langage naturel** : Comprend les intentions de l'utilisateur.
*   **Structuration** : G√©n√®re un JSON standardis√© d√©finissant le but, les entr√©es, les sorties et les contraintes de l'agent demand√©.
*   **Architecture Hexagonale** : Code propre, testable et d√©coupl√©.

## üõ†Ô∏è Installation

1.  **Pr√©requis** : Python 3.10+
2.  **Cloner le projet** (si ce n'est pas d√©j√† fait).
3.  **Installer les d√©pendances** :
    ```bash
    pip install -r interpretation_service/requirements.txt
    ```
4.  **Configuration** :
    *   Copiez `.env.example` vers `.env`.
    *   Ajoutez votre cl√© API Groq dans `.env` :
        ```env
        GROQ_API_KEY=gsk_...
        GROQ_MODEL=llama3-70b-8192
        ```

## üéÆ Utilisation

Il y a trois fa√ßons d'interagir avec l'agent :

### 1. Interface Web (Recommand√©)

C'est la m√©thode la plus conviviale, incluant le chat multi-tours.

1.  Lancez le serveur API :
    ```bash
    python -m uvicorn interpretation_service.interfaces.api.http_api:app --reload
    ```
2.  Ouvrez le fichier `interpretation_service/interfaces/api/static/index.html` dans votre navigateur.
3.  Discutez avec l'assistant !

### 2. API HTTP

Pour int√©grer l'agent dans d'autres syst√®mes.

#### Endpoint de Chat (Conversation Gateway)
*   **Endpoint** : `POST /chat`
*   **Payload** :
    ```json
    {
      "session_id": "session_123",
      "user_id": "user_123",
      "message": "Je veux un agent qui surveille le prix du Bitcoin",
      "metadata": {}
    }
    ```
*   **R√©ponse** :
    ```json
    {
      "session_id": "session_123",
      "reply": "D'accord, sur quelle plateforme voulez-vous surveiller le prix ?",
      "done": false,
      "agent_spec": null
    }
    ```
    (Quand `done` est `true`, `agent_spec` contient la sp√©cification finale).

#### Endpoint d'Interpr√©tation Directe (Core)
*   **Endpoint** : `POST /interpret`
*   **Payload** :
    ```json
    {
      "user_id": "user_123",
      "text": "R√©sum√© complet du besoin...",
      "metadata": {}
    }
    ```

### 3. Ligne de Commande (CLI)

Pour tester rapidement le moteur d'interpr√©tation sans le chat.

```bash
python -m interpretation_service.interfaces.cli.simulate_request
```

## üèóÔ∏è Architecture

Le projet suit l'architecture hexagonale (Ports & Adapters) :

*   `domain/` : Mod√®les (`conversation_models.py`, `models.py`) et logique m√©tier pure.
*   `application/` :
    *   `conversation/` : Service de gestion du chat (`ConversationAgentService`).
    *   `services/` : Service d'interpr√©tation (`RequestInterpreterService`).
*   `ports/` : Interfaces abstraites (pour le LLM, le STT, le Bus, la M√©moire).
*   `infrastructure/` : Impl√©mentations concr√®tes (Groq, In-Memory, etc.).
*   `interfaces/` : Points d'entr√©e (CLI, API HTTP).
