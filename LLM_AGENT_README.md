# AgentModeles

`AgentModeles` is a Python class for automatic generation of Python functions using AI models via the Groq API. It supports multiple model types:

- LLM (text generation)
- Speech-to-Text (transcription)
- Text-to-Speech (synthesis)
- Text-to-Video (generation)
- Image generation

## Inputs

- **description** (`str`): Textual description of the function to generate
- **inputs** (`dict[str, str]`): Dictionary of input parameter names and types
- **outputs** (`dict[str, str]`): Dictionary of output names and types
- **model_type** (`str`): Type of model to use (`llm`, `speech_to_text`, `text_to_speech`, `text_to_video`, `image_generation`)
- **constraints** (`str`, optional): Additional constraints for the function
- **temperature** (`float`, optional): Generation creativity (default: 0.3)
- **max_tokens** (`int`, optional): Maximum tokens to generate (default: 2048)

## Outputs

The main output of the class is a dictionary containing:

- `source_code`: The generated Python code as a string
- `context`: A detailed professional context in markdown
- `prompt`: The prompt sent to the LLM
- `metadata`: Structured metadata about the function, model, and generation parameters

## Main Functions

- `__init__()`: Initializes the agent and Groq client (requires `GROQ_API_KEY` in environment)
- `generate_model_function(description, inputs, outputs, model_type, constraints, temperature, max_tokens)`: Generates a Python function based on the provided description and parameters
- `build_prompt(...)`: Builds the prompt for the LLM using templates
- `call_llm(prompt, temperature, max_tokens)`: Calls the Groq LLM API
- `parse_llm_output(llm_raw_output)`: Parses the LLM output to extract code and metadata
- `get_available_models()`: Returns available model types and their descriptions

## Example Usage

```python
from advanced_generator import AgentModeles

agent = AgentModeles()
result = agent.generate_model_function(
	description="Summarize a text.",
	inputs={"text": "str"},
	outputs={"summary": "str"},
	model_type="llm"
)
print(result["source_code"])
```

## Requirements

- Python 3.8+
- `groq` package (`pip install groq`)
- Set the environment variable `GROQ_API_KEY` with your API key

## Prompts Directory

Prompt templates must be present in the `prompts/` directory. The class loads and uses these templates for building prompts for different model types.

---
*Generated by GitHub Copilot*